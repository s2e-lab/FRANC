{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompts(filename):\n",
    "    with open(filename) as f:\n",
    "        prompts = []\n",
    "        for line in f:\n",
    "            prompts.append(json.loads(line))\n",
    "    return prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "benchmark_root = \"../Quality_Analyzer/Quality_Filtered_Suggestions/\"\n",
    "dir_list = os.listdir(benchmark_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_folder_root = './Quality_Codes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file:  SecurityEval_python_codeparrot-small_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Processing file:  SOEvalJava_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  28\n",
      "Processing file:  CoderEval4Python_prompt_codeparrot_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Processing file:  SOEvalPython_codegen-350M-mono_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Processing file:  HumanEval_java_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  161\n",
      "Processing file:  SecurityEval_python_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Processing file:  HumanEval_python_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Processing file:  SOEvalJava_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  28\n",
      "Processing file:  CoderEval4Python_prompt_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Processing file:  SecurityEval_python_codegen-2B-mono_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Processing file:  CoderEval4Java_prompt_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Processing file:  HumanEval_python_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Processing file:  HumanEval_python_codegen-350M-mono_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Processing file:  aiXcoder_prompt_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  175\n",
      "Processing file:  CoderEval4Python_prompt_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  230\n",
      "Processing file:  HumanEval_java_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  161\n",
      "Processing file:  HumanEval_python_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  164\n",
      "Processing file:  aiXcoder_prompt_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  175\n",
      "Processing file:  SOEvalPython_codeparrot-small_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Processing file:  HumanEval_java_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  161\n",
      "Processing file:  SOEvalPython_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Processing file:  SecurityEval_python_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Processing file:  SOEvalPython_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Processing file:  SOEvalJava_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  28\n",
      "Processing file:  SOEvalJava_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  28\n",
      "Processing file:  HumanEval_python_codeparrot_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Processing file:  SOEvalPython_codeparrot_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Processing file:  SOEvalPython_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  42\n",
      "Processing file:  SecurityEval_python_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Processing file:  CoderEval4Python_prompt_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Processing file:  aiXcoder_prompt_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  175\n",
      "Processing file:  aiXcoder_prompt_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  175\n",
      "Processing file:  CoderEval4Java_prompt_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Processing file:  HumanEval_java_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  161\n",
      "Processing file:  SOEvalJava_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  28\n",
      "Processing file:  SecurityEval_python_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  121\n",
      "Processing file:  CoderEval4Python_prompt_codegen-2B-mono_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Processing file:  CoderEval4Python_prompt_codegen-350M-mono_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Processing file:  CoderEval4Python_prompt_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Processing file:  HumanEval_python_codegen-2B-mono_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Processing file:  SecurityEval_python_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Processing file:  SOEvalPython_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Processing file:  CoderEval4Python_prompt_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Processing file:  HumanEval_python_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Processing file:  SecurityEval_python_codegen-350M-mono_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Processing file:  aiXcoder_prompt_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  175\n",
      "Processing file:  CoderEval4Python_prompt_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Processing file:  CoderEval4Python_prompt_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Processing file:  SecurityEval_python_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Processing file:  HumanEval_java_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  161\n",
      "Processing file:  HumanEval_java_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  161\n",
      "Processing file:  SOEvalJava_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  28\n",
      "Processing file:  CoderEval4Java_prompt_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  230\n",
      "Processing file:  CoderEval4Java_prompt_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Processing file:  CoderEval4Python_prompt_codeparrot-small_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Processing file:  SOEvalPython_codegen-2B-mono_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Processing file:  SOEvalPython_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Processing file:  SOEvalPython_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Processing file:  HumanEval_python_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Processing file:  CoderEval4Java_prompt_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Processing file:  aiXcoder_prompt_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  175\n",
      "Processing file:  HumanEval_python_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Processing file:  CoderEval4Java_prompt_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Processing file:  SecurityEval_python_codeparrot_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Processing file:  aiXcoder_prompt_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  175\n",
      "Processing file:  HumanEval_python_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Processing file:  HumanEval_java_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  161\n",
      "Processing file:  SOEvalPython_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Processing file:  SOEvalJava_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  28\n",
      "Processing file:  CoderEval4Java_prompt_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Processing file:  HumanEval_python_codeparrot-small_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Processing file:  SecurityEval_python_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Total number of vulnerable prompts:  2271\n",
      "Total number of vulnerable items:  5661\n"
     ]
    }
   ],
   "source": [
    "count_total_vulnerable_prompt = 0\n",
    "count_total_vulnerable_item = 0\n",
    "\n",
    "file_list = {}\n",
    "for file in dir_list:\n",
    "    if \".DS_Store\" in file:\n",
    "        continue\n",
    "    file_list[file] = {\n",
    "        \"prompt_ids\": [],\n",
    "        \"prompt_count\": 0\n",
    "    }\n",
    "\n",
    "    print(\"Processing file: \", file)\n",
    "    benchmark_path = os.path.join(benchmark_root, file)\n",
    "    prompts = get_prompts(benchmark_path)\n",
    "    print(\"Number of prompts: \", len(prompts))\n",
    "    count_prompt = 0\n",
    "    count_item = 0\n",
    "    for prompt in prompts:\n",
    "        is_vulnerable_prompt = False\n",
    "        for i in range(len(prompt[\"suggestions\"])):\n",
    "            suggestion = prompt[\"suggestions\"][i]\n",
    "            if suggestion[\"Is_Vulnerable\"]:\n",
    "                is_vulnerable_prompt = True\n",
    "                count_item+=1\n",
    "               \n",
    "        if is_vulnerable_prompt:\n",
    "            count_prompt+=1\n",
    "            file_list[file][\"prompt_ids\"].append(prompt['task_id'])\n",
    "    file_list[file][\"prompt_count\"] = count_prompt\n",
    "\n",
    "    count_total_vulnerable_item+=count_item\n",
    "    count_total_vulnerable_prompt+=count_prompt\n",
    "\n",
    "\n",
    "print(\"Total number of vulnerable prompts: \", count_total_vulnerable_prompt)\n",
    "print(\"Total number of vulnerable items: \", count_total_vulnerable_item)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_population = 329"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file:  SecurityEval_python_codeparrot-small_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of vulnerable prompts:  57\n",
      "Target population for file:  8\n",
      "Processing file:  SecurityEval_python_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of vulnerable prompts:  65\n",
      "Target population for file:  9\n",
      "Processing file:  SecurityEval_python_codegen-2B-mono_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of vulnerable prompts:  59\n",
      "Target population for file:  9\n",
      "Processing file:  SecurityEval_python_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of vulnerable prompts:  55\n",
      "Target population for file:  8\n",
      "Processing file:  SecurityEval_python_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of vulnerable prompts:  24\n",
      "Target population for file:  3\n",
      "Processing file:  SecurityEval_python_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of vulnerable prompts:  47\n",
      "Target population for file:  7\n",
      "Processing file:  SecurityEval_python_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of vulnerable prompts:  48\n",
      "Target population for file:  7\n",
      "Processing file:  SecurityEval_python_codegen-350M-mono_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of vulnerable prompts:  58\n",
      "Target population for file:  8\n",
      "Processing file:  SecurityEval_python_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of vulnerable prompts:  60\n",
      "Target population for file:  9\n",
      "Processing file:  SecurityEval_python_codeparrot_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of vulnerable prompts:  55\n",
      "Target population for file:  8\n",
      "Processing file:  SecurityEval_python_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of vulnerable prompts:  49\n",
      "Target population for file:  7\n",
      "Total number of samples:  83\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_samples = 0\n",
    "for file in dir_list:\n",
    "    if \"Security\" not in file:\n",
    "        continue\n",
    "    if 'SOEval' in file:\n",
    "        code_folder = \"_\".join(file.split('_')[0:1])\n",
    "    else:\n",
    "        code_folder = \"_\".join(file.split('_')[0:2])\n",
    "    if not os.path.exists(code_folder_root+code_folder):\n",
    "        os.mkdir(code_folder_root+code_folder)\n",
    "    \n",
    "    \n",
    "    if 'SOEval' in file:\n",
    "        model = file.split('_')[1]\n",
    "    else:\n",
    "        model = file.split('_')[2]\n",
    "    if not os.path.exists(code_folder_root+code_folder+'/'+model):\n",
    "        os.mkdir(code_folder_root+code_folder+'/'+model)\n",
    "\n",
    "    path_to_file = code_folder_root+code_folder+'/'+model+'/'\n",
    "    extension = \".java\"\n",
    "    if 'python' in file.lower():\n",
    "        extension = \".py\"\n",
    "    \n",
    "    print(\"Processing file: \", file)\n",
    "    benchmark_path = os.path.join(benchmark_root, file)\n",
    "    prompts = get_prompts(benchmark_path)\n",
    "    print(\"Number of prompts: \", len(prompts))\n",
    "\n",
    "    print(\"Number of vulnerable prompts: \", len(file_list[file][\"prompt_ids\"]))\n",
    "\n",
    "    target_population_for_file = round((len(file_list[file][\"prompt_ids\"])*target_population)/count_total_vulnerable_prompt)\n",
    "    print(\"Target population for file: \", target_population_for_file)\n",
    "    total_samples+=target_population_for_file\n",
    "\n",
    "    sample_list = random.sample(file_list[file][\"prompt_ids\"], target_population_for_file)\n",
    "    assert len(sample_list) == target_population_for_file\n",
    "    file_list[file][\"sampled_prompt_ids\"] = sample_list\n",
    "\n",
    "    # print(\"Original list: \", file_list[file][\"prompt_ids\"])\n",
    "    # print(\"Sample list: \", sample_list)\n",
    "    for prompt in prompts:\n",
    "        current_list = []\n",
    "        for i in range(len(prompt[\"suggestions\"])):\n",
    "            suggestion = prompt[\"suggestions\"][i]\n",
    "            if prompt['task_id'] in sample_list:\n",
    "                file_name = str(prompt['task_id']).replace(\"/\",\"_\")+'_'+str(i)+extension\n",
    "                with open(path_to_file+file_name, 'w') as f:\n",
    "                    f.write(suggestion['fixed_generated_text'])\n",
    "                current_list.append({\"Model\": file, \"Prompt_ID\": prompt['task_id'] , \"Suggestion_ID\":str(i), \"Suggestion\": suggestion['fixed_generated_text'],\"Is_Compilable\":int(suggestion[\"Is_Compilable\"]), \"Is_Vulnerable\": int(suggestion['Is_Vulnerable'])})\n",
    "        if len(current_list)>0:\n",
    "            new_current_list = sorted(current_list, key=lambda k: k['Is_Compilable'], reverse=True)\n",
    "\n",
    "            new_compilable_list = []\n",
    "            new_non_compilable_list = []\n",
    "            for item in new_current_list:\n",
    "                if item['Is_Compilable']:\n",
    "                    new_compilable_list.append(item)\n",
    "                else:\n",
    "                    new_non_compilable_list.append(item)\n",
    "            \n",
    "            new_compilable_list = sorted(new_compilable_list, key=lambda k: k['Is_Vulnerable'])\n",
    "            new_current_list = new_compilable_list + new_non_compilable_list\n",
    "            # print(current_list, len(current_list))\n",
    "            # print(new_current_list, len(new_current_list))\n",
    "            df = df.append(new_current_list, ignore_index=True)\n",
    "print(\"Total number of samples: \", total_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['Model', 'Prompt_ID'], inplace=True, ascending=False)\n",
    "df.to_csv(\"sampled_prompts.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
