{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompts(filename):\n",
    "    with open(filename) as f:\n",
    "        prompts = []\n",
    "        for line in f:\n",
    "            prompts.append(json.loads(line))\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_root = \"../Quality_Analyzer/Quality_Filtered_Suggestions/\"\n",
    "dir_list = os.listdir(benchmark_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "repair_root =\"../Repair_Benchmarks_2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_up_to_line(code: str, line_number: int) -> str:\n",
    "    lines = code.splitlines()\n",
    "    return \"\\n\".join(lines[:line_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "total_prompts = 0\n",
    "for file in dir_list:\n",
    "    if \".DS_Store\" in file:\n",
    "        continue\n",
    "    result[file] = {}\n",
    "    prompt_list = []\n",
    "    print(\"Processing file: \", file)\n",
    "    benchmark_path = os.path.join(benchmark_root, file)\n",
    "    prompts = get_prompts(benchmark_path)\n",
    "    print(\"Number of prompts: \", len(prompts))\n",
    "    dataset_type = \"Java\"\n",
    "    if 'python' in file.lower():\n",
    "        dataset_type = \"Python\"\n",
    "    \n",
    "    total_time = 0\n",
    "    for prompt in prompts:\n",
    "        # print(\"Prompt: \", prompt[\"task_id\"])\n",
    "\n",
    "        total_correct_suggestions = 0\n",
    "        repair_prompt = None\n",
    "\n",
    "        for i in range(len(prompt[\"suggestions\"])):\n",
    "            suggestion = prompt[\"suggestions\"][i]\n",
    "            if suggestion[\"Is_Vulnerable\"]:\n",
    "                if repair_prompt is None:\n",
    "                    repair_prompt = suggestion\n",
    "            if not suggestion[\"Is_Vulnerable\"] and suggestion[\"Is_Compilable\"]:\n",
    "                 total_correct_suggestions += 1\n",
    "\n",
    "        if total_correct_suggestions == 0 and repair_prompt is not None:\n",
    "                start_time = time.time()\n",
    "                new_prompt = prompt.copy()\n",
    "                new_prompt.pop(\"suggestions\", None)\n",
    "                new_prompt[\"task_id\"] = str(new_prompt[\"task_id\"])\n",
    "                new_prompt[\"old_prompt\"] = repair_prompt[\"fixed_generated_text\"]\n",
    "                new_prompt[\"repair_prompt\"] = repair_prompt[\"fixed_generated_text\"]\n",
    "                prompt_text = \"\"\n",
    "                if \"Security\" in file:\n",
    "                    total_prompt_line = len(new_prompt[\"Prompt\"].splitlines())\n",
    "                else:\n",
    "                    total_prompt_line = len(new_prompt[\"prompt\"].splitlines())\n",
    "\n",
    "                is_first_time = False\n",
    "                if dataset_type == \"Python\":\n",
    "                    for j in range(len(repair_prompt[\"Analyzer_Result\"])):\n",
    "                        if repair_prompt[\"Analyzer_Result\"][j][\"line_number\"]<=total_prompt_line:\n",
    "                            continue\n",
    "                        if is_first_time == False:\n",
    "                            new_prompt[\"repair_prompt\"] = get_code_up_to_line(repair_prompt[\"fixed_generated_text\"], repair_prompt[\"Analyzer_Result\"][j][\"line_number\"]-1)+\"\\n\"\n",
    "                            is_first_time = True\n",
    "                        new_prompt[\"repair_prompt\"] += \"# Fix: \" + repair_prompt[\"Analyzer_Result\"][j][\"issue_text\"]+\"\\n\"\n",
    "                else:\n",
    "                    if type(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"]) is list:\n",
    "                        for j in range(len(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"])):\n",
    "                            \n",
    "                            if type(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"SourceLine\"]) is list:\n",
    "                                    for k in range(len(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"SourceLine\"])):\n",
    "                                        if \"@start\" in repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"SourceLine\"][k]:\n",
    "                                            line_no = int(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"SourceLine\"][k][\"@start\"])\n",
    "                                            if line_no<=total_prompt_line:\n",
    "                                                continue\n",
    "                                            if is_first_time == False:\n",
    "                                                new_prompt[\"repair_prompt\"] = get_code_up_to_line(repair_prompt[\"fixed_generated_text\"], line_no-1)+\"\\n\"\n",
    "                                                is_first_time = True\n",
    "                                            new_prompt[\"repair_prompt\"] += \"// Fix: \" +  repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"ShortMessage\"]+\"\\n\"\n",
    "                                            # print(prompt_text)\n",
    "                                        else:\n",
    "                                            pass\n",
    "                                            # print(prompt_text)\n",
    "                            else:\n",
    "                                if \"@start\" in repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"SourceLine\"]:\n",
    "                                    line_no = int(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"SourceLine\"][\"@start\"])\n",
    "                                    if line_no<=total_prompt_line:\n",
    "                                        continue\n",
    "                                    if is_first_time == False:\n",
    "                                        new_prompt[\"repair_prompt\"] = get_code_up_to_line(repair_prompt[\"fixed_generated_text\"], line_no-1)+\"\\n\"\n",
    "                                        is_first_time = True\n",
    "                                    new_prompt[\"repair_prompt\"] += \"// Fix: \" +  repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"ShortMessage\"]+\"\\n\"\n",
    "                                    # print(prompt_text)\n",
    "                                else:\n",
    "                                    pass\n",
    "                                    # print(prompt_text)\n",
    "                    else:\n",
    "                        if type(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"SourceLine\"]) is list:\n",
    "                            for j in range(len(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"SourceLine\"])):\n",
    "                                if \"@start\" in repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"SourceLine\"][j]:\n",
    "                                    line_no = int(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"SourceLine\"][j][\"@start\"])\n",
    "                                    if line_no<=total_prompt_line:\n",
    "                                        continue\n",
    "                                    if is_first_time == False:\n",
    "                                        new_prompt[\"repair_prompt\"] = get_code_up_to_line(repair_prompt[\"fixed_generated_text\"], line_no-1)+\"\\n\"\n",
    "                                        is_first_time = True\n",
    "                                    new_prompt[\"repair_prompt\"] += \"// Fix: \" +  repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"ShortMessage\"]+\"\\n\"\n",
    "                                    # print(prompt_text)\n",
    "                                else:\n",
    "                                    pass\n",
    "\n",
    "                                    # print(prompt_text)\n",
    "                        else:\n",
    "                            if \"@start\" in repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"SourceLine\"]:\n",
    "                                line_no = int(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"SourceLine\"][\"@start\"])\n",
    "                                if line_no<=total_prompt_line:\n",
    "                                        continue\n",
    "                                if is_first_time == False:\n",
    "                                    new_prompt[\"repair_prompt\"] = get_code_up_to_line(repair_prompt[\"fixed_generated_text\"], line_no-1)+\"\\n\"\n",
    "                                    is_first_time = True\n",
    "                                new_prompt[\"repair_prompt\"] += \"// Fix: \" + repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"ShortMessage\"]+\"\\n\"\n",
    "                                # print(prompt_text)\n",
    "                            else:\n",
    "                                pass\n",
    "                                # print(prompt_text)\n",
    "                \n",
    "                # if \"Security\" in file:\n",
    "                #     new_prompt[\"repair_prompt\"] += prompt_text+\"\\n\"#+new_prompt[\"Prompt\"]\n",
    "                # else:\n",
    "                #     new_prompt[\"repair_prompt\"] += prompt_text+\"\\n\"#+new_prompt[\"prompt\"]\n",
    "                if is_first_time == False:\n",
    "                    continue\n",
    "                if dataset_type == \"Python\":\n",
    "                    new_prompt[\"repair_prompt\"] += \"\\n# Fixed Code: \\n\"\n",
    "                else:\n",
    "                    new_prompt[\"repair_prompt\"] += \"\\n// Fixed Code: \\n\"\n",
    "                prompt_list.append(new_prompt)\n",
    "\n",
    "                total_time += time.time() - start_time\n",
    "\n",
    "    print(\"Number of new prompts: \", len(prompt_list))\n",
    "    total_prompts += len(prompt_list)\n",
    "    repair_path = os.path.join(repair_root, file)\n",
    "    with open(repair_path, 'w') as f:\n",
    "        for prompt in prompt_list:\n",
    "            f.write(json.dumps(prompt))\n",
    "            f.write(\"\\n\")\n",
    "    result[file][\"total_time\"] = total_time\n",
    "print(\"Total prompts: \", total_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file:  SecurityEval_python_codeparrot-small_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  23\n",
      "Processing file:  SOEvalJava_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  28\n",
      "Number of new prompts:  1\n",
      "Processing file:  CoderEval4Python_prompt_codeparrot_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  0\n",
      "Processing file:  SOEvalPython_codegen-350M-mono_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  2\n",
      "Processing file:  HumanEval_java_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  161\n",
      "Number of new prompts:  15\n",
      "Processing file:  SecurityEval_python_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  24\n",
      "Processing file:  HumanEval_python_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  SOEvalJava_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  28\n",
      "Number of new prompts:  1\n",
      "Processing file:  CoderEval4Python_prompt_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  0\n",
      "Processing file:  SecurityEval_python_codegen-2B-mono_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  23\n",
      "Processing file:  CoderEval4Java_prompt_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  10\n",
      "Processing file:  HumanEval_python_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  HumanEval_python_codegen-350M-mono_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  aiXcoder_prompt_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  175\n",
      "Number of new prompts:  0\n",
      "Processing file:  CoderEval4Python_prompt_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  5\n",
      "Processing file:  HumanEval_java_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  161\n",
      "Number of new prompts:  2\n",
      "Processing file:  HumanEval_python_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  1\n",
      "Processing file:  aiXcoder_prompt_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  175\n",
      "Number of new prompts:  16\n",
      "Processing file:  SOEvalPython_codeparrot-small_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  2\n",
      "Processing file:  HumanEval_java_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  161\n",
      "Number of new prompts:  11\n",
      "Processing file:  SOEvalPython_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  2\n",
      "Processing file:  SecurityEval_python_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  22\n",
      "Processing file:  SOEvalPython_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  2\n",
      "Processing file:  SOEvalJava_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  28\n",
      "Number of new prompts:  1\n",
      "Processing file:  SOEvalJava_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  28\n",
      "Number of new prompts:  1\n",
      "Processing file:  HumanEval_python_codeparrot_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  SOEvalPython_codeparrot_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  2\n",
      "Processing file:  SOEvalPython_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  0\n",
      "Processing file:  SecurityEval_python_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  22\n",
      "Processing file:  CoderEval4Python_prompt_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  0\n",
      "Processing file:  aiXcoder_prompt_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  175\n",
      "Number of new prompts:  18\n",
      "Processing file:  aiXcoder_prompt_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  175\n",
      "Number of new prompts:  10\n",
      "Processing file:  CoderEval4Java_prompt_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  9\n",
      "Processing file:  HumanEval_java_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  161\n",
      "Number of new prompts:  13\n",
      "Processing file:  SOEvalJava_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  28\n",
      "Number of new prompts:  1\n",
      "Processing file:  SecurityEval_python_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  26\n",
      "Processing file:  CoderEval4Python_prompt_codegen-2B-mono_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  0\n",
      "Processing file:  CoderEval4Python_prompt_codegen-350M-mono_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  1\n",
      "Processing file:  CoderEval4Python_prompt_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  0\n",
      "Processing file:  HumanEval_python_codegen-2B-mono_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  SecurityEval_python_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  22\n",
      "Processing file:  SOEvalPython_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  2\n",
      "Processing file:  CoderEval4Python_prompt_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  0\n",
      "Processing file:  HumanEval_python_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  SecurityEval_python_codegen-350M-mono_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  24\n",
      "Processing file:  aiXcoder_prompt_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  175\n",
      "Number of new prompts:  15\n",
      "Processing file:  CoderEval4Python_prompt_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  0\n",
      "Processing file:  CoderEval4Python_prompt_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  0\n",
      "Processing file:  SecurityEval_python_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  24\n",
      "Processing file:  HumanEval_java_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  161\n",
      "Number of new prompts:  5\n",
      "Processing file:  HumanEval_java_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  161\n",
      "Number of new prompts:  3\n",
      "Processing file:  SOEvalJava_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  28\n",
      "Number of new prompts:  1\n",
      "Processing file:  CoderEval4Java_prompt_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  7\n",
      "Processing file:  CoderEval4Java_prompt_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  9\n",
      "Processing file:  CoderEval4Python_prompt_codeparrot-small_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  1\n",
      "Processing file:  SOEvalPython_codegen-2B-mono_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  2\n",
      "Processing file:  SOEvalPython_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  2\n",
      "Processing file:  SOEvalPython_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  2\n",
      "Processing file:  HumanEval_python_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  CoderEval4Java_prompt_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  4\n",
      "Processing file:  aiXcoder_prompt_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  175\n",
      "Number of new prompts:  13\n",
      "Processing file:  HumanEval_python_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  CoderEval4Java_prompt_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  8\n",
      "Processing file:  SecurityEval_python_codeparrot_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  24\n",
      "Processing file:  aiXcoder_prompt_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  175\n",
      "Number of new prompts:  15\n",
      "Processing file:  HumanEval_python_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  HumanEval_java_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  161\n",
      "Number of new prompts:  21\n",
      "Processing file:  SOEvalPython_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  0\n",
      "Processing file:  SOEvalJava_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  28\n",
      "Number of new prompts:  1\n",
      "Processing file:  CoderEval4Java_prompt_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  8\n",
      "Processing file:  HumanEval_python_codeparrot-small_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  SecurityEval_python_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  23\n",
      "Total prompts:  502\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "total_prompts = 0\n",
    "for file in dir_list:\n",
    "    if \".DS_Store\" in file:\n",
    "        continue\n",
    "    result[file] = {}\n",
    "    prompt_list = []\n",
    "    print(\"Processing file: \", file)\n",
    "    benchmark_path = os.path.join(benchmark_root, file)\n",
    "    prompts = get_prompts(benchmark_path)\n",
    "    print(\"Number of prompts: \", len(prompts))\n",
    "    dataset_type = \"Java\"\n",
    "    if 'python' in file.lower():\n",
    "        dataset_type = \"Python\"\n",
    "    \n",
    "    total_time = 0\n",
    "    for prompt in prompts:\n",
    "        # print(\"Prompt: \", prompt[\"task_id\"])\n",
    "\n",
    "        total_correct_suggestions = 0\n",
    "        repair_prompt = None\n",
    "\n",
    "        for i in range(len(prompt[\"suggestions\"])):\n",
    "            suggestion = prompt[\"suggestions\"][i]\n",
    "            if suggestion[\"Is_Vulnerable\"]:\n",
    "                if repair_prompt is None:\n",
    "                    repair_prompt = suggestion\n",
    "            if not suggestion[\"Is_Vulnerable\"] and suggestion[\"Is_Compilable\"]:\n",
    "                 total_correct_suggestions += 1\n",
    "\n",
    "        if total_correct_suggestions == 0 and repair_prompt is not None:\n",
    "                start_time = time.time()\n",
    "                new_prompt = prompt.copy()\n",
    "                new_prompt.pop(\"suggestions\", None)\n",
    "                new_prompt[\"task_id\"] = str(new_prompt[\"task_id\"])\n",
    "                new_prompt[\"old_prompt\"] = repair_prompt[\"fixed_generated_text\"]\n",
    "                new_prompt[\"repair_prompt\"] = repair_prompt[\"fixed_generated_text\"]\n",
    "                prompt_text = \"\"\n",
    "                \n",
    "                if dataset_type == \"Python\":\n",
    "                    for j in range(len(repair_prompt[\"Analyzer_Result\"])):\n",
    "                        prompt_text += \"\\n# Fix: At line \" + str(repair_prompt[\"Analyzer_Result\"][j][\"line_number\"]) + \", \" + repair_prompt[\"Analyzer_Result\"][j][\"issue_text\"]\n",
    "                        # print(prompt_text)\n",
    "                else:\n",
    "                    if type(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"]) is list:\n",
    "                        for j in range(len(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"])):\n",
    "                            \n",
    "                            if type(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"SourceLine\"]) is list:\n",
    "                                    for k in range(len(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"SourceLine\"])):\n",
    "                                        if \"@start\" in repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"SourceLine\"][k]:\n",
    "                                            prompt_text += \"\\n// Fix: At line \" + str(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"SourceLine\"][k][\"@start\"]) + \", \" + repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"ShortMessage\"]\n",
    "                                            # print(prompt_text)\n",
    "                                        else:\n",
    "                                            prompt_text += \"\\n// Fix: \"+ repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"ShortMessage\"]\n",
    "                                            # print(prompt_text)\n",
    "                            else:\n",
    "                                if \"@start\" in repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"SourceLine\"]:\n",
    "                                    prompt_text += \"\\n// Fix: At line \" + str(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"SourceLine\"][\"@start\"]) + \", \" + repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"ShortMessage\"]\n",
    "                                    # print(prompt_text)\n",
    "                                else:\n",
    "                                    prompt_text += \"\\n// Fix: \"+ repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"ShortMessage\"]\n",
    "                                    # print(prompt_text)\n",
    "                    else:\n",
    "                        if type(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"SourceLine\"]) is list:\n",
    "                            for j in range(len(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"SourceLine\"])):\n",
    "                                if \"@start\" in repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"SourceLine\"][j]:\n",
    "                                    prompt_text += \"\\n// Fix: At line \" + str(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"SourceLine\"][j][\"@start\"]) + \", \" + repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"ShortMessage\"]\n",
    "                                    # print(prompt_text)\n",
    "                                else:\n",
    "                                    prompt_text += \"\\n// Fix: \"+ repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"ShortMessage\"]\n",
    "                                    # print(prompt_text)\n",
    "                        else:\n",
    "                            if \"@start\" in repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"SourceLine\"]:\n",
    "                                prompt_text += \"\\n// Fix: At line \" + str(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"SourceLine\"][\"@start\"]) + \", \" + repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"ShortMessage\"]\n",
    "                                # print(prompt_text)\n",
    "                            else:\n",
    "                                prompt_text += \"\\n// Fix: \"+ repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"ShortMessage\"]\n",
    "                                # print(prompt_text)\n",
    "                \n",
    "                if \"Security\" in file:\n",
    "                    new_prompt[\"repair_prompt\"] += prompt_text+\"\\n\"#+new_prompt[\"Prompt\"]\n",
    "                else:\n",
    "                    new_prompt[\"repair_prompt\"] += prompt_text+\"\\n\"#+new_prompt[\"prompt\"]\n",
    "                if dataset_type == \"Python\":\n",
    "                    new_prompt[\"repair_prompt\"] += \"\\n# Fixed Code: \\n\"\n",
    "                else:\n",
    "                    new_prompt[\"repair_prompt\"] += \"\\n// Fixed Code: \\n\"\n",
    "                prompt_list.append(new_prompt)\n",
    "                total_time += time.time() - start_time\n",
    "\n",
    "    print(\"Number of new prompts: \", len(prompt_list))\n",
    "    total_prompts += len(prompt_list)\n",
    "    repair_path = os.path.join(repair_root, file)\n",
    "    with open(repair_path, 'w') as f:\n",
    "        for prompt in prompt_list:\n",
    "            f.write(json.dumps(prompt))\n",
    "            f.write(\"\\n\")\n",
    "    result[file][\"total_time\"] = total_time\n",
    "print(\"Total prompts: \", total_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9d/98myd0lx1rn2j76hx3t96x1r0000gn/T/ipykernel_18376/3097771823.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"repair_time.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(result, orient='index')\n",
    "df.head()\n",
    "df.to_csv(\"repair_time.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>total_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CoderEval4Java_prompt_PolyCoder-0.4B_128_10.jsonl</td>\n",
       "      <td>CoderEval4Java_prompt</td>\n",
       "      <td>PolyCoder-0.4B</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CoderEval4Java_prompt_PolyCoder-160M_128_10.jsonl</td>\n",
       "      <td>CoderEval4Java_prompt</td>\n",
       "      <td>PolyCoder-160M</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CoderEval4Java_prompt_PolyCoder-2.7B_128_10.jsonl</td>\n",
       "      <td>CoderEval4Java_prompt</td>\n",
       "      <td>PolyCoder-2.7B</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CoderEval4Java_prompt_codegen-2B-multi_128_10....</td>\n",
       "      <td>CoderEval4Java_prompt</td>\n",
       "      <td>codegen-2B-multi</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CoderEval4Java_prompt_codegen-350M-multi_128_1...</td>\n",
       "      <td>CoderEval4Java_prompt</td>\n",
       "      <td>codegen-350M-multi</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Unnamed: 0                Dataset  \\\n",
       "0  CoderEval4Java_prompt_PolyCoder-0.4B_128_10.jsonl  CoderEval4Java_prompt   \n",
       "1  CoderEval4Java_prompt_PolyCoder-160M_128_10.jsonl  CoderEval4Java_prompt   \n",
       "2  CoderEval4Java_prompt_PolyCoder-2.7B_128_10.jsonl  CoderEval4Java_prompt   \n",
       "3  CoderEval4Java_prompt_codegen-2B-multi_128_10....  CoderEval4Java_prompt   \n",
       "4  CoderEval4Java_prompt_codegen-350M-multi_128_1...  CoderEval4Java_prompt   \n",
       "\n",
       "                Model  total_time  \n",
       "0      PolyCoder-0.4B    0.000042  \n",
       "1      PolyCoder-160M    0.000046  \n",
       "2      PolyCoder-2.7B    0.000039  \n",
       "3    codegen-2B-multi    0.000031  \n",
       "4  codegen-350M-multi    0.000032  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"repair_time.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(x):\n",
    "    if 'SOEval' in x:\n",
    "       return \"_\".join(x.split('_')[0:1])\n",
    "    else:\n",
    "        return \"_\".join(x.split('_')[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(x):\n",
    "    if 'SOEval' in x:\n",
    "        return x.split('_')[1]\n",
    "    else:\n",
    "        return x.split('_')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language(x):\n",
    "    dataset_type = \"Java\"\n",
    "    if \"python\" in x.lower():\n",
    "        dataset_type = \"Python\"\n",
    "    return dataset_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(3, \"Language\", df[\"Unnamed: 0\"].apply(get_language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"repair_time.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Language</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PolyCoder-0.4B</th>\n",
       "      <th>Java</th>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PolyCoder-160M</th>\n",
       "      <th>Java</th>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolyCoder-2.7B</th>\n",
       "      <th>Java</th>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         total_time\n",
       "Model          Language            \n",
       "PolyCoder-0.4B Java        0.000040\n",
       "               Python      0.000027\n",
       "PolyCoder-160M Java        0.000037\n",
       "               Python      0.000014\n",
       "PolyCoder-2.7B Java        0.000030"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"repair_time.csv\")\n",
    "grouped_df = df.groupby([\"Model\",\"Language\"]).mean()\n",
    "grouped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.to_csv(\"grouped_repair_time.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Language</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PolyCoder-0.4B</th>\n",
       "      <th>Java</th>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PolyCoder-160M</th>\n",
       "      <th>Java</th>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PolyCoder-2.7B</th>\n",
       "      <th>Java</th>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegen-2B-mono</th>\n",
       "      <th>Python</th>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">codegen-2B-multi</th>\n",
       "      <th>Java</th>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegen-350M-mono</th>\n",
       "      <th>Python</th>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">codegen-350M-multi</th>\n",
       "      <th>Java</th>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codeparrot</th>\n",
       "      <th>Python</th>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codeparrot-small</th>\n",
       "      <th>Python</th>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gpt3.5</th>\n",
       "      <th>Java</th>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">incoder-1B</th>\n",
       "      <th>Java</th>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             total_time\n",
       "Model              Language            \n",
       "PolyCoder-0.4B     Java        0.000040\n",
       "                   Python      0.000027\n",
       "PolyCoder-160M     Java        0.000037\n",
       "                   Python      0.000014\n",
       "PolyCoder-2.7B     Java        0.000030\n",
       "                   Python      0.000015\n",
       "codegen-2B-mono    Python      0.000016\n",
       "codegen-2B-multi   Java        0.000037\n",
       "                   Python      0.000018\n",
       "codegen-350M-mono  Python      0.000019\n",
       "codegen-350M-multi Java        0.000038\n",
       "                   Python      0.000015\n",
       "codeparrot         Python      0.000022\n",
       "codeparrot-small   Python      0.000098\n",
       "gpt3.5             Java        0.000045\n",
       "                   Python      0.000021\n",
       "incoder-1B         Java        0.000023\n",
       "                   Python      0.000011"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
