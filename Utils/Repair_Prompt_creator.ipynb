{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompts(filename):\n",
    "    with open(filename) as f:\n",
    "        prompts = []\n",
    "        for line in f:\n",
    "            prompts.append(json.loads(line))\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_root = \"../Quality_Analyzer/Quality_Filtered_Suggestions/\"\n",
    "dir_list = os.listdir(benchmark_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "repair_root =\"../Repair_Benchmarks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file:  SecurityEval_python_codeparrot-small_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  23\n",
      "Processing file:  SOEvalJava_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  28\n",
      "Number of new prompts:  1\n",
      "Processing file:  CoderEval4Python_prompt_codeparrot_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  0\n",
      "Processing file:  SOEvalPython_codegen-350M-mono_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  2\n",
      "Processing file:  HumanEval_java_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  161\n",
      "Number of new prompts:  15\n",
      "Processing file:  SecurityEval_python_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  24\n",
      "Processing file:  HumanEval_python_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  SOEvalJava_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  28\n",
      "Number of new prompts:  1\n",
      "Processing file:  CoderEval4Python_prompt_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  0\n",
      "Processing file:  SecurityEval_python_codegen-2B-mono_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  23\n",
      "Processing file:  CoderEval4Java_prompt_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  10\n",
      "Processing file:  HumanEval_python_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  HumanEval_python_codegen-350M-mono_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  aiXcoder_prompt_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  175\n",
      "Number of new prompts:  0\n",
      "Processing file:  CoderEval4Python_prompt_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  5\n",
      "Processing file:  HumanEval_java_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  161\n",
      "Number of new prompts:  2\n",
      "Processing file:  HumanEval_python_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  1\n",
      "Processing file:  aiXcoder_prompt_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  175\n",
      "Number of new prompts:  16\n",
      "Processing file:  SOEvalPython_codeparrot-small_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  2\n",
      "Processing file:  HumanEval_java_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  161\n",
      "Number of new prompts:  11\n",
      "Processing file:  SOEvalPython_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  2\n",
      "Processing file:  SecurityEval_python_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  22\n",
      "Processing file:  SOEvalPython_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  2\n",
      "Processing file:  SOEvalJava_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  28\n",
      "Number of new prompts:  1\n",
      "Processing file:  SOEvalJava_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  28\n",
      "Number of new prompts:  1\n",
      "Processing file:  HumanEval_python_codeparrot_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  SOEvalPython_codeparrot_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  2\n",
      "Processing file:  SOEvalPython_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  0\n",
      "Processing file:  SecurityEval_python_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  22\n",
      "Processing file:  CoderEval4Python_prompt_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  0\n",
      "Processing file:  aiXcoder_prompt_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  175\n",
      "Number of new prompts:  18\n",
      "Processing file:  aiXcoder_prompt_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  175\n",
      "Number of new prompts:  10\n",
      "Processing file:  CoderEval4Java_prompt_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  9\n",
      "Processing file:  HumanEval_java_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  161\n",
      "Number of new prompts:  13\n",
      "Processing file:  SOEvalJava_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  28\n",
      "Number of new prompts:  1\n",
      "Processing file:  SecurityEval_python_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  26\n",
      "Processing file:  CoderEval4Python_prompt_codegen-2B-mono_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  0\n",
      "Processing file:  CoderEval4Python_prompt_codegen-350M-mono_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  1\n",
      "Processing file:  CoderEval4Python_prompt_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  0\n",
      "Processing file:  HumanEval_python_codegen-2B-mono_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  SecurityEval_python_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  22\n",
      "Processing file:  SOEvalPython_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  2\n",
      "Processing file:  CoderEval4Python_prompt_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  0\n",
      "Processing file:  HumanEval_python_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  SecurityEval_python_codegen-350M-mono_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  24\n",
      "Processing file:  aiXcoder_prompt_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  175\n",
      "Number of new prompts:  15\n",
      "Processing file:  CoderEval4Python_prompt_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  0\n",
      "Processing file:  CoderEval4Python_prompt_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  0\n",
      "Processing file:  SecurityEval_python_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  24\n",
      "Processing file:  HumanEval_java_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  161\n",
      "Number of new prompts:  5\n",
      "Processing file:  HumanEval_java_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  161\n",
      "Number of new prompts:  3\n",
      "Processing file:  SOEvalJava_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  28\n",
      "Number of new prompts:  1\n",
      "Processing file:  CoderEval4Java_prompt_gpt3.5_512_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  7\n",
      "Processing file:  CoderEval4Java_prompt_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  9\n",
      "Processing file:  CoderEval4Python_prompt_codeparrot-small_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  1\n",
      "Processing file:  SOEvalPython_codegen-2B-mono_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  2\n",
      "Processing file:  SOEvalPython_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  2\n",
      "Processing file:  SOEvalPython_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  2\n",
      "Processing file:  HumanEval_python_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  CoderEval4Java_prompt_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  4\n",
      "Processing file:  aiXcoder_prompt_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  175\n",
      "Number of new prompts:  13\n",
      "Processing file:  HumanEval_python_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  CoderEval4Java_prompt_codegen-2B-multi_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  8\n",
      "Processing file:  SecurityEval_python_codeparrot_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  24\n",
      "Processing file:  aiXcoder_prompt_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  175\n",
      "Number of new prompts:  15\n",
      "Processing file:  HumanEval_python_PolyCoder-0.4B_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  HumanEval_java_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  161\n",
      "Number of new prompts:  21\n",
      "Processing file:  SOEvalPython_incoder-1B_128_10.jsonl\n",
      "Number of prompts:  42\n",
      "Number of new prompts:  0\n",
      "Processing file:  SOEvalJava_PolyCoder-2.7B_128_10.jsonl\n",
      "Number of prompts:  28\n",
      "Number of new prompts:  1\n",
      "Processing file:  CoderEval4Java_prompt_codegen-350M-multi_128_10.jsonl\n",
      "Number of prompts:  230\n",
      "Number of new prompts:  8\n",
      "Processing file:  HumanEval_python_codeparrot-small_128_10.jsonl\n",
      "Number of prompts:  164\n",
      "Number of new prompts:  0\n",
      "Processing file:  SecurityEval_python_PolyCoder-160M_128_10.jsonl\n",
      "Number of prompts:  121\n",
      "Number of new prompts:  23\n",
      "Total prompts:  502\n"
     ]
    }
   ],
   "source": [
    "total_prompts = 0\n",
    "for file in dir_list:\n",
    "    if \".DS_Store\" in file:\n",
    "        continue\n",
    "    \n",
    "    prompt_list = []\n",
    "    print(\"Processing file: \", file)\n",
    "    benchmark_path = os.path.join(benchmark_root, file)\n",
    "    prompts = get_prompts(benchmark_path)\n",
    "    print(\"Number of prompts: \", len(prompts))\n",
    "    dataset_type = \"Java\"\n",
    "    if 'python' in file.lower():\n",
    "        dataset_type = \"Python\"\n",
    "    for prompt in prompts:\n",
    "        # print(\"Prompt: \", prompt[\"task_id\"])\n",
    "\n",
    "        total_correct_suggestions = 0\n",
    "        repair_prompt = None\n",
    "\n",
    "        for i in range(len(prompt[\"suggestions\"])):\n",
    "            suggestion = prompt[\"suggestions\"][i]\n",
    "            if suggestion[\"Is_Vulnerable\"]:\n",
    "                if repair_prompt is None:\n",
    "                    repair_prompt = suggestion\n",
    "            if not suggestion[\"Is_Vulnerable\"] and suggestion[\"Is_Compilable\"]:\n",
    "                 total_correct_suggestions += 1\n",
    "        if total_correct_suggestions == 0 and repair_prompt is not None:\n",
    "                new_prompt = prompt.copy()\n",
    "                new_prompt.pop(\"suggestions\", None)\n",
    "                new_prompt[\"task_id\"] = str(new_prompt[\"task_id\"])\n",
    "                new_prompt[\"old_prompt\"] = repair_prompt[\"fixed_generated_text\"]\n",
    "                new_prompt[\"repair_prompt\"] = repair_prompt[\"fixed_generated_text\"]\n",
    "                prompt_text = \"\"\n",
    "                if dataset_type == \"Python\":\n",
    "                    for j in range(len(repair_prompt[\"Analyzer_Result\"])):\n",
    "                        prompt_text += \"\\n# Fix: At line \" + str(repair_prompt[\"Analyzer_Result\"][j][\"line_number\"]) + \", \" + repair_prompt[\"Analyzer_Result\"][j][\"issue_text\"]\n",
    "                        # print(prompt_text)\n",
    "                else:\n",
    "                    if type(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"]) is list:\n",
    "                        for j in range(len(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"])):\n",
    "                            \n",
    "                            if type(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"SourceLine\"]) is list:\n",
    "                                    for k in range(len(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"SourceLine\"])):\n",
    "                                        if \"@start\" in repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"SourceLine\"][k]:\n",
    "                                            prompt_text += \"\\n// Fix: At line \" + str(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"SourceLine\"][k][\"@start\"]) + \", \" + repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"ShortMessage\"]\n",
    "                                            # print(prompt_text)\n",
    "                                        else:\n",
    "                                            prompt_text += \"\\n// Fix: \"+ repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"ShortMessage\"]\n",
    "                                            # print(prompt_text)\n",
    "                            else:\n",
    "                                if \"@start\" in repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"SourceLine\"]:\n",
    "                                    prompt_text += \"\\n// Fix: At line \" + str(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"SourceLine\"][\"@start\"]) + \", \" + repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"ShortMessage\"]\n",
    "                                    # print(prompt_text)\n",
    "                                else:\n",
    "                                    prompt_text += \"\\n// Fix: \"+ repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][j][\"ShortMessage\"]\n",
    "                                    # print(prompt_text)\n",
    "                    else:\n",
    "                        if type(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"SourceLine\"]) is list:\n",
    "                            for j in range(len(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"SourceLine\"])):\n",
    "                                if \"@start\" in repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"SourceLine\"][j]:\n",
    "                                    prompt_text += \"\\n// Fix: At line \" + str(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"SourceLine\"][j][\"@start\"]) + \", \" + repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"ShortMessage\"]\n",
    "                                    # print(prompt_text)\n",
    "                                else:\n",
    "                                    prompt_text += \"\\n// Fix: \"+ repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"ShortMessage\"]\n",
    "                                    # print(prompt_text)\n",
    "                        else:\n",
    "                            if \"@start\" in repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"SourceLine\"]:\n",
    "                                prompt_text += \"\\n// Fix: At line \" + str(repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"SourceLine\"][\"@start\"]) + \", \" + repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"ShortMessage\"]\n",
    "                                # print(prompt_text)\n",
    "                            else:\n",
    "                                prompt_text += \"\\n// Fix: \"+ repair_prompt[\"Analyzer_Result\"][\"BugCollection\"][\"BugInstance\"][\"ShortMessage\"]\n",
    "                                # print(prompt_text)\n",
    "                if \"Security\" in file:\n",
    "                    new_prompt[\"repair_prompt\"] += prompt_text+\"\\n\"+new_prompt[\"Prompt\"]\n",
    "                else:\n",
    "                    new_prompt[\"repair_prompt\"] += prompt_text+\"\\n\"+new_prompt[\"prompt\"]\n",
    "                prompt_list.append(new_prompt)\n",
    "\n",
    "    print(\"Number of new prompts: \", len(prompt_list))\n",
    "    total_prompts += len(prompt_list)\n",
    "    repair_path = os.path.join(repair_root, file)\n",
    "    with open(repair_path, 'w') as f:\n",
    "        for prompt in prompt_list:\n",
    "            f.write(json.dumps(prompt))\n",
    "            f.write(\"\\n\")\n",
    "print(\"Total prompts: \", total_prompts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
